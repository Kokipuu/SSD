{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path as osp\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    " \n",
    "from utils.ssd_model import VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n",
    "from utils.ssd_model import SSD\n",
    "from utils.ssd_model import MultiBoxLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = 'YOUR_ROOT_PATH'\n",
    "sys.path.append(ROOT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのリストを取得\n",
    "data_path = 'YOUR_DATA_PATH'\n",
    "\n",
    "filename_list = [os.path.split(f)[1].split('.')[0] for f in glob.glob(f'{data_path}/*.xml')]\n",
    "filename_list_train, filename_list_val = train_test_split(filename_list, test_size=0.1)\n",
    "train_img_list = [f'{data_path}/{f}.jpg' for f in filename_list_train]\n",
    "train_anno_list = [f'{data_path}/{f}.xml' for f in filename_list_train]\n",
    "val_img_list = [f'{data_path}/{f}.jpg' for f in filename_list_val]\n",
    "val_anno_list = [f'{data_path}/{f}.xml' for f in filename_list_val]\n",
    " \n",
    "# Datasetを作成\n",
    "voc_classes = ['cop']\n",
    " \n",
    "color_mean = (104, 117, 123)  # (BGR)の色の平均値\n",
    "input_size = 300  # 画像のinputサイズ\n",
    " \n",
    "train_dataset = VOCDataset(train_img_list, \n",
    "                           train_anno_list, \n",
    "                           phase=\"train\", \n",
    "                           transform=DataTransform(input_size, color_mean), \n",
    "                           transform_anno=Anno_xml2list(voc_classes))\n",
    "val_dataset = VOCDataset(val_img_list, \n",
    "                         val_anno_list, \n",
    "                         phase=\"val\", \n",
    "                         transform=DataTransform(input_size, color_mean), \n",
    "                         transform_anno=Anno_xml2list(voc_classes))\n",
    " \n",
    "# DataLoaderを作成\n",
    "train_dataloader = data.DataLoader(train_dataset, \n",
    "                                   batch_size=32, \n",
    "                                   shuffle=True, \n",
    "                                   collate_fn=od_collate_fn)\n",
    "val_dataloader = data.DataLoader(val_dataset, \n",
    "                                 batch_size=3, \n",
    "                                 shuffle=False, \n",
    "                                 collate_fn=od_collate_fn)\n",
    " \n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSD300の設定\n",
    "ssd_cfg = {\n",
    "    'num_classes': 2,  # 背景クラスを含めた合計クラス数\n",
    "    'input_size': 300,  # 画像の入力サイズ\n",
    "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 出力するDBoxのアスペクト比の種類\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],  # 各sourceの画像サイズ\n",
    "    'steps': [8, 16, 32, 64, 100, 300],  # DBOXの大きさを決める\n",
    "    'min_sizes': [21, 45, 99, 153, 207, 261],  # DBOXの大きさを決める\n",
    "    'max_sizes': [45, 99, 153, 207, 261, 315],  # DBOXの大きさを決める\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    " \n",
    "# SSDネットワークモデル\n",
    "net = SSD(phase=\"train\", cfg=ssd_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSDの初期の重みを設定\n",
    "vgg16_weight_path = 'VGG16_WEIGHT_PATH'\n",
    "vgg_weights = torch.load(vgg16_weight_path)\n",
    "net.vgg.load_state_dict(vgg_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssdのその他のネットワークの重みはHeの初期値で初期化\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:  # バイアス項がある場合\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "        \n",
    "# Heの初期値を適用\n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)\n",
    " \n",
    "# GPUが使えるかを確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "criterion = MultiBoxLoss(jaccard_thresh=0.5, neg_pos=3, device=device)\n",
    " \n",
    "# 最適化手法の設定\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    " \n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    " \n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    " \n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    " \n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0  # epochの損失和\n",
    "    epoch_val_loss = 0.0  # epochの損失和\n",
    "    min_loss = 9999\n",
    "    logs = []\n",
    " \n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs+1):\n",
    " \n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    " \n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    " \n",
    "            # データローダーからminibatchずつ取り出すループ\n",
    "            with tqdm(dataloaders_dict[phase], desc=phase, file=sys.stdout) as iterator:\n",
    "                for images, targets in iterator:\n",
    " \n",
    "                    # GPUが使えるならGPUにデータを送る\n",
    "                    images = images.to(device)\n",
    "                    targets = [ann.to(device)\n",
    "                               for ann in targets]  # リストの各要素のテンソルをGPUへ\n",
    " \n",
    "                    # optimizerを初期化\n",
    "                    optimizer.zero_grad()\n",
    " \n",
    "                    # 順伝搬（forward）計算\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        # 順伝搬（forward）計算\n",
    "                        outputs = net(images)\n",
    " \n",
    "                        # 損失の計算\n",
    "                        loss_l, loss_c = criterion(outputs, targets)\n",
    "                        loss = loss_l + loss_c\n",
    " \n",
    "                        # 訓練時はバックプロパゲーション\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            nn.utils.clip_grad_value_(net.parameters(), clip_value=2.0)\n",
    "                            optimizer.step()\n",
    "                            epoch_train_loss += loss.item()\n",
    "                            iteration += 1\n",
    "                        # 検証時\n",
    "                        else:\n",
    "                            epoch_val_loss += loss.item()\n",
    " \n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print(f'epoch {epoch+1}/{num_epochs} {(t_epoch_finish - t_epoch_start):.4f}sec || train_Loss:{epoch_train_loss:.4f} val_Loss:{epoch_val_loss:.4f}')\n",
    "        t_epoch_start = time.time()\n",
    " \n",
    "        # vallossが小さい、ネットワークを保存する\n",
    "        if min_loss>epoch_val_loss:\n",
    "            min_loss=epoch_val_loss\n",
    "            trian_weight_path = 'YOUR_TRAIN_PATH'\n",
    "            torch.save(net.state_dict(), trian_weight_path)\n",
    " \n",
    "        epoch_train_loss = 0.0  # epochの損失和\n",
    "        epoch_val_loss = 0.0  # epochの損失和\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
